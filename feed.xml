<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jiantingfeng.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jiantingfeng.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-06T15:28:12+00:00</updated><id>https://jiantingfeng.github.io/feed.xml</id><title type="html">blank</title><subtitle>Jianting Feng&apos;s personal website. </subtitle><entry><title type="html">Hutchinson’s Trace Estimation</title><link href="https://jiantingfeng.github.io/2023/05/29/hutchinsons-trace-estimation.html" rel="alternate" type="text/html" title="Hutchinson’s Trace Estimation"/><published>2023-05-29T00:00:00+00:00</published><updated>2023-05-29T00:00:00+00:00</updated><id>https://jiantingfeng.github.io/2023/05/29/hutchinsons-trace-estimation</id><content type="html" xml:base="https://jiantingfeng.github.io/2023/05/29/hutchinsons-trace-estimation.html"><![CDATA[<h1 id="intuition">Intuition</h1> <p>Given a matrix \(A\in \mathbb{R}^{n\times n}\), if we want to compute its trace, then we can use this trick, called <em>Hutchinson’s Trace Estimation</em>.</p> <p>The intuition of Hutchinson’s trace estimator is <strong>replace matrix-matrix product by matrix-vector product, and use Monte-Carlo to estimate the trace</strong></p> \[\mathrm{tr}\left(A\right) = \mathrm{tr}\left(A\mathbb{E}[\varepsilon \varepsilon^T]\right)=\mathbb{E}\left[\mathrm{tr}(A\varepsilon\varepsilon^T)\right]=\mathbb{E}\left[\mathrm{tr}(\varepsilon^TA\varepsilon)\right] = \mathbb{E}\left[\varepsilon^T A \varepsilon\right]\] <p>where \(\varepsilon\sim \mathcal{N}(0, I)\in\mathbb{R}^n\), then you can use Monte Carlo method to approximate the expectation.</p> <p>But, why don’t we directly calculate the trace?</p> <p>Suppose you need to calculate the trace of a matrix function, i.e. \(\mathrm{tr}(A^2), \mathrm{tr}( A^3)\), etc</p> <p>By traditional way, you should go through the following steps</p> <ul> <li> <p>Calculate the Jordan canonical form of \(A\) . Indeed, in numerical computation, every matrix is diagonalizable since all eigenvalues are different (approximation error). Then the cost of this step takes \(\mathcal{O}(n^3)\) , the diag. form is denoted as \(\Lambda\)</p> </li> <li> <p>Calculate \(f(\Lambda)\) , and add them up to calculate trace, which takes \(\mathcal{O}(n)\)</p> </li> </ul> <p>Total time complexity is \(\mathcal{O}(n^3)\)</p> <p>If we use <em>Hutchinson’s Trace Estimation</em> to estimate \(\mathrm{tr} A^2\)</p> <ul> <li>For \(t=0, 1, \cdots, T\) do <ul> <li>Draw \(\varepsilon\sim \mathcal{N}(0, I)\in\mathbb{R}^n\)</li> <li>Calculate \(\varepsilon^T A^2\varepsilon\), you can calculate vector-matrix product rather than matrix-matrix product, which takes \(\mathcal{O}(n^2)\)</li> </ul> </li> <li>Calculate the average of previous results, takes \(\mathcal{O}(T)\)</li> <li>Total time complexity is \(\mathcal{O}(n^2T)\)</li> </ul> <p>The vector \(\varepsilon\) is referred as <em>probe vector</em>. If the number of probe vector is smaller than the dimension \(n\), we can reduce the time complexity.</p> <h1 id="formal-statement-and-property">Formal Statement and Property</h1> <p>W.I.P.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Intuition]]></summary></entry><entry><title type="html">Ito Lemma and Stochastic Differential Equation</title><link href="https://jiantingfeng.github.io/probability/financial/2023/05/27/ito-lemma-and-stochastic-differential-equation.html" rel="alternate" type="text/html" title="Ito Lemma and Stochastic Differential Equation"/><published>2023-05-27T20:00:00+00:00</published><updated>2023-05-27T20:00:00+00:00</updated><id>https://jiantingfeng.github.io/probability/financial/2023/05/27/ito-lemma-and-stochastic-differential-equation</id><content type="html" xml:base="https://jiantingfeng.github.io/probability/financial/2023/05/27/ito-lemma-and-stochastic-differential-equation.html"><![CDATA[<h1 id="martingales-in-discrete-time">Martingales in Discrete Time</h1> <h2 id="conditional-expectation">Conditional expectation</h2> <p>If \(\mathbf X\) is a random variable, then \(\mathbb{E} \mathbf X\) can be thought as the best guess for \(\mathbf X\) given no extra information. A conditional expectation can be viewed as the best guass given certain information.</p> <p>Let \(\mathbf X_1, \mathbf X_2,\cdots\) be a series of random variables. At time \(n\) we have wiewed the first \(n\) values \(\mathbf X_1, \cdots, \mathbf X_n\). If \(\mathbf Y\) is another random variable, then</p> \[\mathbb{E}\left[\mathbf Y\vert \mathbf X_1, \cdots, \mathbf X_n\right]\] <p>can be thought as the best guess given \(\mathbf X_1, \cdots, \mathbf X_n\). \(\mathcal{F}_n\) represents the information contained in \(\mathbf X_1, \cdots, \mathbf X_n\), and \(\mathcal{F}_0\) contains no information. We have following property</p> <ol> <li>If we have no information, then the best guess is the unconditional expectation, \(\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_0\right] = \mathbb{E}\left[\mathbf{Y}\right]\)</li> <li>The conditional exepctation \(\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_n\right]\) should only contain the information up to time \(n\), we say \(\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_n\right]\) is \(\mathcal{F}_n\)-measurable, i.e.</li> </ol> \[\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_n\right] = \varphi(\mathbf{X}_1, \cdots, \mathbf{X}_n)\] <p>A basic property of conditional expectation is that</p> \[\mathbb{E}\left[\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_n\right]\right] = \mathbb{E}\left[\mathbf{Y}\right]\] <p>Besides, conditional expectation is linear, which means, for any \(a, b\in \mathbb{R}\) and random variable \(\mathbf{Y, Z}\), we have</p> \[\mathbb{E}\left[a\mathbf{Y}+b\mathbf{Z}\vert \mathcal{F}_n\right] = a\mathbb{E}\left[\mathbf{Y}\vert \mathcal{F}_n\right] + b\mathbb{E}\left[\mathbf{Z}\vert \mathcal{F}_n\right]\] <h2 id="martingales">Martingales</h2> <p>Martingale is a concept for modeling the fair game. Suppose \(\mathbf{X}_1, \mathbf{X}_2, \cdots\) is a sequence of random variables associated with filtration \(\left\{\mathcal{F}n\right\}\). A sequence of random variables \(\mathbf{M}0, \mathbf{M}1, \cdots\) is called a <em>martingale</em> w.r.t. filtration \(\left\{\mathcal{F}n\right\}\) if:</p> <ol> <li>For each \(n\), \(\mathbf{M}_n\) is \(\mathcal{F}_n\) measurable with \(\mathbb{E}\left[\lvert \mathbf{M}_n\rvert\right]&lt; \infty\)]</li> <li>If \(m &gt; n\), then</li> </ol> \[\mathbb{E}\left[\mathbf{M}_n\vert \mathcal{F}_m\right] = \mathbf{M}_m.\] <p>We can also define a <em>submartingale</em> as</p> \[\mathbb{E}\left[\mathbf{M}_n\vert \mathcal{F}_m\right] \leq \mathbf{M}_m\] <p>and a <em>supermartingale</em></p> \[\mathbb{E}\left[\mathbf{M}_n\vert \mathcal{F}_m\right] \geq \mathbf{M}_m\] <p>Note: For all “fair” games you play in casino, they are always submartingale since you have to pay commission.</p> <h1 id="brownian-motion">Brownian Motion</h1> <h2 id="limits-of-sums-of-independent-variables">Limits of sums of independent variables</h2> <p>Suppose \(\mathbf{X}_1, \mathbf{X}_2,\cdots, \mathbf{X}_n\) are i.i.d. random variables with mean \(\mu\) and variance \(\sigma^2&lt;\infty\). Let</p> \[\mathbf{Z}_n = \dfrac{\left(\mathbf{X}_1 + \cdots + \mathbf{X}_n\right) - n\mu}{\sigma\sqrt{n}}\] <p>Let \(\Phi(b)\) be the c.d.f. of standard Gaussian, i.e.</p> \[\Phi(b) = \int_{-\infty}^b \dfrac{1}{\sqrt{2\pi}} e^{-x^2/2} \mathrm{d} x\] <p>By central limit theorem,</p> \[\lim_{n\to\infty} \mathbb{P}\left[a\leq Z_n\leq b\right] = \Phi(b) - \Phi(a)\] <p>the proof of CLT can be easily derived by the characteristic function.</p> <h2 id="limits-of-random-walks">Limits of random walks</h2> <p>Brownian motion can be viewed as the limit of random walk as the time and space increments tends to zero. Suppose \(\mathbf{X}_1, \mathbf{X}_2, \cdots\) are independent random variables with \(\mathbb{P}\left[\mathbf{X}_j = 1\right] = \mathbb{P}\left[\mathbf{X}_j = -1\right] = \dfrac{1}{2}\) and let</p> \[S_n = X_1 + \cdots + X_n\] <p>here we suppose time and space difference \(\Delta x = 1, \Delta t = 1\). If we choose time increment as \(\Delta t = \dfrac{1}{N}\) where \(N\) is sufficiently large, we view the process at</p> \[\Delta t, 2\Delta t, 3\Delta t, \cdots\] <p>and at each time step we have a jump \(\pm \Delta x\), the value of the process will be</p> \[W_1^{N} = \Delta x\left(X_1 + \cdots + X_N\right)\] <p>we would like to choose \(\text{Var}\left(W_1^N\right) = 1\), i.e.</p> \[\begin{align*} \text{Var}\left(W_1^{N}\right) &amp; = \left(\Delta x\right)\left(\text{Var}X_1 + \cdots + \text{Var}X_N\right) \\ &amp; = \left(\Delta x\right)^2\cdot N = 1 \\ \end{align*}\] <p>we get \(\Delta x = \dfrac{1}{\sqrt{N}}\), note how we choose \(\Delta t\), we deduce that</p> \[\Delta x = \sqrt{\Delta t}\] <h2 id="brownian-motion-1">Brownian Motion</h2> <p><em>Brownian motion</em> or <em>Wiener process</em> is a model of continuous random process. Let \(B_t = B(t)\) be the value at time \(t\), \(B_t\) is a random variable. A collection of random variable indexed by time is called a <em>stochastic process</em>.</p> <p>There are three major assumptions about \(B_t\)</p> <ol> <li><strong>Stationary increments</strong>. \(s &lt; t\), then the distribution of \(B_t - B_s\) is identical to the distribution of \(B_{t-s}\),</li> <li><strong>Independent increments</strong>. If \(s &lt; t\), then the random variable \(B_t - B_s\) is independent of \(B_r\) if \(r &lt; s\),</li> <li><strong>Continuous path</strong>. The function \(t\mapsto B_t\) is continuous (i.e. H"older continuous with exponent equals \(1/ 2\) ).</li> </ol> <p>For convenience, we often set \(B_0 = 0\).</p> <p>A stochastic process \(B_t\) is called (one-dimensional) <em>Brownian motion</em> if it satisfies the following.</p> <ol> <li>\(B_0 = 0\),</li> <li>For \(s &lt; t\), \(B_t - B_s \sim \mathcal{N}\left((t-s)m, (t-s)\sigma^2\right)\) where \(m\) is \textit{drift} and \(\sigma^2\) is <em>variance</em>,</li> <li>If \(s &lt; t\), then \(B_t - B_s\) is independent of \(B_r\) if \(r &lt; s\),</li> <li>With probability \(1\), the function \(t\mapsto B_t\) is continuous.</li> </ol> <p>If \(m = 0\) and \(\sigma^2 = 1\), then \(B_t\) is called <em>standard Brownian motion</em>.</p> <p>Recall the reparameterization trick of standard Gaussian, take \(B_t\) as standard Brownian motion, then</p> \[Y_t = \sigma B_t + mt\] <p>is a Brownian motion with drift \(m\) and variance \(\sigma^2\).</p> <h1 id="ito-integral">Ito Integral</h1> <h2 id="ito-process">Ito Process</h2> <p>Let \(W_t\) denote the standard Brownian motion, we define the <em>Ito process</em> as following</p> <p>Let \(X_t\) be a stochastic process, \(X_t\) is called an <em>Ito process</em> if it satisfies the following stochastic differential equation,</p> \[\mathrm{d} X_t = \underbrace{\mu\left(t, X_t\right) \mathrm{d} t}_{\text{drifting term}} + \underbrace{\sigma\left(t, X_t\right) \mathrm{d} W_t}_{\text{diffusion term}}\] <p>where \(\mu\) and \(\sigma\) are functions of \(t\) and \(X_t\). Remembering the definition of Riemann integral, we can not integrate the stochastic differential equation directly. We need to define a new integral to solve the equation. Which is called \textit{It\^o integral}.</p> <h2 id="ito-integral-1">Ito Integral</h2> <p>Recall the way we solve ordinary differential equation, we can use the following method to solve stochastic differential equation.</p> <p>Let \(f(x, t)\) be a second order differentiable function, we can calculate the Taylor expansion of it as:</p> \[\mathrm{d} f = \dfrac{\partial f}{\partial x} \mathrm{d} x + \dfrac{\partial f}{\partial t} \mathrm{d} t + \dfrac{1}{2} \dfrac{\partial^2 f}{\partial x^2} \mathrm{d} x^2 + \dfrac{1}{2} \dfrac{\partial^2 f}{\partial t^2} \mathrm{d} t^2 + \dfrac{\partial^2 f}{\partial x \partial t} \mathrm{d} x \mathrm{d} t\] <p>substitute \(\mathrm dx\) with \(\mathrm{d}X_t = \mu\left(t, X_t\right) \mathrm{d} t + \sigma\left(t, X_t\right)\mathrm{d}W_t\), recall that \(\left(\mathrm{d}W_t\right)^2 = \mathrm{d}t\) (magic happens here), ignore the high-order term, we get</p> \[\mathrm{d} f = \left(\dfrac{\partial f}{\partial t} + \mu\left(t, X_t\right)\dfrac{\partial f}{\partial x} + \dfrac{\sigma\left(t, X_t\right)^2}{2}\dfrac{\partial^2 f}{\partial x^2}\right) \mathrm{d}t + \sigma\left(t, X_t\right)\dfrac{\partial f}{\partial x} \mathrm{d}W_t\] <p>The equation above is called <em>Ito’s lemma</em> . It is the key to solve stochastic differential equation.</p> <p>Consider \(X_t = W_t^2\), we use Ito’s lemma to calculate \(\mathrm{d}X_t\).</p> \[\begin{align*} \mathrm{d}X_t &amp; = \left(\dfrac{\partial f}{\partial t} + \mu\left(t, X_t\right)\dfrac{\partial f}{\partial x} + \dfrac{\sigma\left(t, X_t\right)^2}{2}\dfrac{\partial^2 f}{\partial x^2}\right) \mathrm{d}t + \sigma\left(t, X_t\right)\dfrac{\partial f}{\partial x} \mathrm{d}W_t \\ &amp; = \left(0 + 0 + \dfrac{1}{2}\cdot 2\cdot 1\right) \mathrm{d}t + 2W_t \mathrm{d}W_t \\ &amp; = \mathrm{d}t + 2W_t \mathrm{d}W_t \end{align*}\] <p>compared to normal differentiation, we have an extra term \(\mathrm{d}t\) term here. On the other hand,</p> \[\int_0^t W_s\mathrm{d}W_s = \dfrac{1}{2}W_t^2 - \dfrac{1}{2}t\] <p>when we reverse the process.</p> <p>This shows we can reverse the process of Ito’s lemma to solve stochastic differential equation.</p> <p>If \(f\) doesn’t contain \(t\), then we can use the following simplyfied form to calculate \(\mathrm{d}f\) (\(\mu=0, \sigma=1\)).</p> \[\mathrm{d}f = f^\prime(X_t) \mathrm{d}X_t + \dfrac{1}{2} \ f^{\prime\prime}(X_t) \mathrm{d}t\] <h3 id="example-geometric-brownian-motion-gbm">Example: Geometric Brownian Motion (GBM)</h3> <p>Geometric Brownian Motion is used to model the stock price. It is defined as</p> \[\mathrm{d}S_t = \mu S_t \mathrm{d}t + \sigma S_t \mathrm{d}W_t\] <p>In order to solve it, take logarithm transformation, i.e. \(\log S_t\), then by It\^o’s lemma,</p> \[\mathrm{d}\log S_t = \dfrac{1}{S_t} \mathrm{d}S_t - \dfrac{1}{2} \dfrac{1}{S_t^2} \mathrm{d}S_t^2 = \left(\mu - \dfrac{1}{2}\sigma^2\right) \mathrm{d}t + \sigma \mathrm{d}W_t\] <p>Integrate both sides, we get the solution</p> \[S_t = S_0 \exp\left(\left(\mu - \dfrac{1}{2}\sigma^2\right)t + \sigma W_t\right)\] <blockquote> <p>The correction term \(\dfrac{1}{2}\sigma^2\) is called \textit{convexity correction}, which comes from the difference between arithmetic mean and geometric mean.</p> </blockquote> <blockquote> <p>We can easily verify whether a process is a martingale by It\^o’s lemma. If the process is a martingale, then the drift term should be zero. For example, \(B_t^2\) is not a martingale, because we have drift term \(- \dfrac{1}{2}\mathrm{d}t\).</p> </blockquote> <p>You can also check whether the following processes are martingales or not, \(W_t\) standards for standard Brownian motion.</p> <ol> <li>\(W_t^3\),</li> <li>\(\dfrac{1}{W_t}\),</li> <li>\(\log W_t\),</li> <li>\(W_t^2 - t\),</li> </ol> <p>All of them are not martingales except the last one.</p>]]></content><author><name></name></author><category term="probability"/><category term="financial"/><summary type="html"><![CDATA[A brief introduction to stochastic differential equation and Ito lemma]]></summary></entry><entry><title type="html">Maximum Mean Discrepancy and Reproduce Kernel Hilbert Space</title><link href="https://jiantingfeng.github.io/machine-learning/2023/05/14/max-mean-des.html" rel="alternate" type="text/html" title="Maximum Mean Discrepancy and Reproduce Kernel Hilbert Space"/><published>2023-05-14T00:00:00+00:00</published><updated>2023-05-14T00:00:00+00:00</updated><id>https://jiantingfeng.github.io/machine-learning/2023/05/14/max-mean-des</id><content type="html" xml:base="https://jiantingfeng.github.io/machine-learning/2023/05/14/max-mean-des.html"><![CDATA[<h2 id="intuition">Intuition</h2> <p>The concept of <em>Maximum Mean Discrepancy</em> is introduced in <a href="https://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf">gretton12a</a> to solve following question:</p> <p>Let \(X\) and \(Y\) be random variables defined on a topological space \(\mathcal{X}\) , with respective Borel probability measure \(p\) and \(q\) . Given observations \(X = \{X_1,\cdots, X_n\}\) and \(Y=\{Y_1, \cdots, Y_m\}\) i.i.d. from \(p\) and \(q\) , respectively. <strong>How can we decided whether</strong> \(p\neq q\)?</p> <p>In other words, we need to measure the <strong>distance</strong> between two group of samples.</p> <h2 id="technique-details">Technique Details</h2> <p>First we have following lemma,</p> <blockquote> <p>Let \((\mathcal X, d)\) be a metric space, and \(p, q\) be two Borel probability measures defined on \(\mathcal X\) . Then \(p=q\) if and only if \(\mathbb{E}_X[f(X)]=\mathbb{E}_Y[f(Y)]\) for all \(f\in C(\mathcal X)\) . Where \(C(\mathcal X)\) denoted the space of bounded continuous functions on \(\mathcal X\).</p> </blockquote> <p>With the help of this lemma, we can turn our problem into an equivalent form:</p> <p>Let \(\mathcal F\in C(\mathcal X)\), we define <em>maximal mean discrepancy</em> (MMD) as</p> \[\textrm{MMD}[\mathcal F, p, q] = \sup_{f\in\mathcal F}\left(\mathbb{E}_X[f(X)] - \mathbb{E}_Y(f(Y)\right)\] <p>where \(x\sim p\) and \(y\sim q\), then \(p = q\) <strong>if and only</strong> \(\textrm{MMD}[\mathcal F, p, q] = 0\).</p> <p><em>MMD</em> is also referred as <strong>integral probability metric</strong>. In practicle, we tends to use a biased empirical estimation of <em>MMD</em>:</p> \[\widehat{\textrm{MMD}}[\mathcal F, X, Y] = \sup_{\varphi\in\mathcal H}\left(\frac{1}{m}\sum_{i=1}^m\varphi(X_i) - \frac{1}{n}\sum_{i=1}^n\varphi(Y_i)\right)\] <p>Here, we restrict the function class in a unit ball of <strong>reproducing kernel Hilbert space</strong> \(\mathcal H\).</p> <p>This empiricial formula seems intractable as well because of the \(\sup\), however, we will illustrate how to get rid of that in the following context. Now, let’s first under an important concept: <em>Reproducing Kernel Hilbert Space</em>.</p> <h3 id="reproducing-kernel-hilbert-space-rkhs">Reproducing Kernel Hilbert Space (RKHS)</h3> <p>Indeed, RKHS is a ubiquitus concept in the field of Machine Learning. In order to figure out what it is, firstly we need some math foundations, I put some useful links here:</p> <ul> <li><a href="https://mathworld.wolfram.com/HilbertSpace.html">Hilbert Space</a></li> <li><a href="https://www.wikiwand.com/en/Riesz_representation_theorem">Riesz Representation Theorem</a></li> <li><a href="https://www.wikiwand.com/en/Kernel_method">Kernel Method</a></li> </ul> <p>The kernel function is a generalization of normal inner product in Euclidan space, with <strong>non-negative, symmetry, and bilinearily</strong>.</p> <p>Given any two data points \(x, x^\prime \in \mathcal X\), together with feature map \(\Phi: \mathcal X\to\mathcal F\subset \mathbb R^{N}\), we can define a <strong>kernel</strong> \(K: \mathcal X\times \mathcal X\to \mathbb R\) as:</p> \[\forall x, x^\prime\in\mathcal X,\qquad K(x, x^\prime) = \langle \Phi(x), \Phi(x^\prime)\rangle = \Phi(x^\prime)^T\Phi(x)\] <p>The reason why we use kernel function rather than original inner product is that: in many machine learning problems, inner product in feature space is extensively (e.g. support vector machine). Normally we don’t use the original form \(\Phi(x)\), which always appears in the form of inner product.</p> <p>then, the Reproducing Kernel Hilbert space is a Hilbert space with <strong>reproducing property</strong>:</p> \[\forall h\in\ \mathcal H, \forall x\in\mathcal X,\qquad h(x) = \langle h, K(x, \cdot)\rangle.\] <p>By the definition of kernel, partial evaluation \(K(x, \cdot)\) is a function from \(\mathcal X\) to \(\mathcal F\) therefore, from the perspective of function space, it can be viewed as the Riesz representation theorem.</p> <p>Recall the evaluation function in RKHS is bounded. By Riesz representation, for all \(x\in\mathcal H\) , \(\exists \phi(x)\in\mathcal H\) , such that the evaluation \(f(x) = \langle f, \phi(x)\rangle_{\mathcal H}\) . The feature map takes the form \(\phi(x) = k(x, \cdot)\) where \(k(\cdot, \cdot)\) is a kernel function defined as \(k(x, z) = \langle\phi(x), \phi(z)\rangle_{\mathcal{H}}\)</p> <ul> <li>This notation can also be extended into expectation, i.e. \(\exists\mu\in\mathcal H\) , \(\forall f\in \mathcal H\) , we have \(\mathbb{E}f = \langle f, \mu\rangle_{\mathcal H}\)</li> <li>We have - \(\mathrm{MMD}^2[\mathcal F, p, q] = \lVert \mu_p - \mu_q \rVert^2\) - Proof is directly followed by the Riesz repr. of expectation.</li> <li>With inner product, it can also be written as \(\langle\mu_p, \mu_p\rangle_{\mathcal H}^2 - 2\langle\mu_p, \mu_q\rangle_{\mathcal H}+\langle\mu_q, \mu_q\rangle_{\mathcal H}^2\)</li> <li>Note that \(\langle\mu_p, \mu_q\rangle_{\mathcal H} = \int_{\mathcal X\times \mathcal X}k(x, z) \mathrm d\mathbb P\mathrm d\mathbb Q\) We can expand the previous form</li> <li>With inner product, it can also be written as \(\langle\mu_p, \mu_p\rangle_{\mathcal H}^2 - 2\langle\mu_p, \mu_q\rangle_{\mathcal H}+\langle\mu_q, \mu_q\rangle_{\mathcal H}^2\) <ul> <li>as expectation of kernel function</li> <li>When do actual calculating, directly use sample expectation to replace the integral.</li> <li>Empirical \(\textrm{MMD}^2 = \frac{1}{m(m-1)}\sum_i\sum_{j\neq i}k(x_i, x_j) - \frac{2}{mn}\sum_i\sum_j k(x_i, z_j) + \frac{1}{n(n-1)}\sum_i\sum_{j\neq i}k(z_i, z_j)\)</li> </ul> </li> <li>you can use different kernel function with different hyperparameters (e,g, bandwidth for Gaussian kernel)</li> </ul>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Introduction of Maximum Mean Discrepancy]]></summary></entry><entry><title type="html">a post with redirect</title><link href="https://jiantingfeng.github.io/2022/02/01/redirect.html" rel="alternate" type="text/html" title="a post with redirect"/><published>2022-02-01T17:39:00+00:00</published><updated>2022-02-01T17:39:00+00:00</updated><id>https://jiantingfeng.github.io/2022/02/01/redirect</id><content type="html" xml:base="https://jiantingfeng.github.io/2022/02/01/redirect.html"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[you can also redirect to assets like pdf]]></summary></entry></feed>